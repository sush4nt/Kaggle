{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f88b7a",
   "metadata": {},
   "source": [
    "Link to the notebook: [here](https://www.kaggle.com/code/cdeotte/tensorflow-gru-starter-0-790)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc5579c",
   "metadata": {
    "papermill": {
     "duration": 0.007669,
     "end_time": "2022-05-30T17:50:37.674356",
     "exception": false,
     "start_time": "2022-05-30T17:50:37.666687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Time Series GRU TensorFlow Starter Notebook\n",
    "In this notebook we present starter code for a time series GRU model and starter code for processing Kaggle's 50GB CSV files into multiple saved NumPy files. Using a time series GRU allows us to use all the provided customer data and not just the customer's last data point. We published plots of time series data [here][1]. In this notebook we\n",
    "* Processes the train data from dataframes into 3D NumPy array of dimensions `num_of_customers x 13 x 188`\n",
    "* Save processed arrays as multiple NumPy files on disk\n",
    "* Next we build and train a GRU from the multiple files on disk\n",
    "* We compute validation score and achieve 0.787\n",
    "* Finally we process and save test data, infer test, and create a submission\n",
    "\n",
    "It is important to note that you **do not need** to process the train and test files every time you run this notebook. Only process the data again when you engineer new features. Otherwise, upload your saved NumPy arrays to a Kaggle dataset (or use my Kaggle dataset [here][2]). Then as you customize and improve your GRU model, set the variable `PROCESS_DATA = False` and `PATH_TO_DATA = [the path to your kaggle dataset]`.\n",
    "\n",
    "To view time series EDA which can help give you intuition about feature engineering and improving model architecture, see my other notebook [here][1]. Note in the code below, we partition the GPU into 8GB for RAPIDS (feature engineering) and 8GB for TensorFlow (model build and train).\n",
    "\n",
    "[1]: https://www.kaggle.com/cdeotte/time-series-eda\n",
    "[2]: https://www.kaggle.com/datasets/cdeotte/amex-data-for-transformers-and-rnns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1d7013",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-05-30T17:50:37.686663Z",
     "iopub.status.busy": "2022-05-30T17:50:37.686266Z",
     "iopub.status.idle": "2022-05-30T17:50:45.829732Z",
     "shell.execute_reply": "2022-05-30T17:50:45.827064Z"
    },
    "papermill": {
     "duration": 8.151909,
     "end_time": "2022-05-30T17:50:45.831906",
     "exception": false,
     "start_time": "2022-05-30T17:50:37.679997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version 2.6.4\n",
      "We will restrict TensorFlow to max 8GB GPU RAM\n",
      "then RAPIDS can use 8GB GPU RAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 17:50:43.437713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 17:50:43.601012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 17:50:43.601842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 17:50:43.604446: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 17:50:43.604780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 17:50:43.605461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 17:50:43.606099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 17:50:45.812070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 17:50:45.813011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 17:50:45.813704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-30 17:50:45.814276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8192 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "print('Using TensorFlow version',tf.__version__)\n",
    "\n",
    "# RESTRICT TENSORFLOW TO 8GB OF GPU RAM\n",
    "# SO THAT WE HAVE 8GB RAM FOR RAPIDS\n",
    "LIMIT = 8\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\n",
    "print('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af5c5fb",
   "metadata": {
    "papermill": {
     "duration": 0.005339,
     "end_time": "2022-05-30T17:50:45.842915",
     "exception": false,
     "start_time": "2022-05-30T17:50:45.837576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Process Train Data\n",
    "We process both train and test data in chunks. We split train data into 10 parts and process each part separately and save to disk. We split test into 20 parts. This allows us to avoid memory errors during processing. We can also perform processing on GPU which is faster than CPU. Discussions about data preprocessing are [here][1] and [here][2]\n",
    "\n",
    "[1]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/327828\n",
    "[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8ac4b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T17:50:45.855818Z",
     "iopub.status.busy": "2022-05-30T17:50:45.854848Z",
     "iopub.status.idle": "2022-05-30T17:50:45.859943Z",
     "shell.execute_reply": "2022-05-30T17:50:45.859116Z"
    },
    "papermill": {
     "duration": 0.013031,
     "end_time": "2022-05-30T17:50:45.861563",
     "exception": false,
     "start_time": "2022-05-30T17:50:45.848532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LOADING JUST FIRST COLUMN OF TRAIN OR TEST IS SLOW\n",
    "# INSTEAD YOU CAN LOAD FIRST COLUMN FROM MY DATASET\n",
    "# OTHERWISE SET VARIABLE TO NONE TO LOAD FROM KAGGLE'S ORIGINAL DATAFRAME\n",
    "PATH_TO_CUSTOMER_HASHES = '../input/amex-data-files/'\n",
    "\n",
    "# AFTER PROCESSING DATA ONCE, UPLOAD TO KAGGLE DATASET\n",
    "# THEN SET VARIABLE BELOW TO FALSE\n",
    "# AND ATTACH DATASET TO NOTEBOOK AND PUT PATH TO DATASET BELOW\n",
    "PROCESS_DATA = True\n",
    "PATH_TO_DATA = './data/'\n",
    "#PATH_TO_DATA = '../input/amex-data-for-transformers-and-rnns/data/'\n",
    "\n",
    "# AFTER TRAINING MODEL, UPLOAD TO KAGGLE DATASET\n",
    "# THEN SET VARIABLE BELOW TO FALSE\n",
    "# AND ATTACH DATASET TO NOTEBOOK AND PUT PATH TO DATASET BELOW\n",
    "TRAIN_MODEL = True\n",
    "PATH_TO_MODEL = './model/'\n",
    "#PATH_TO_MODEL = '../input/amex-data-for-transformers-and-rnns/model/'\n",
    "\n",
    "INFER_TEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56a1d07",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-30T17:50:45.873599Z",
     "iopub.status.busy": "2022-05-30T17:50:45.872947Z",
     "iopub.status.idle": "2022-05-30T17:50:53.683123Z",
     "shell.execute_reply": "2022-05-30T17:50:53.682279Z"
    },
    "papermill": {
     "duration": 7.818119,
     "end_time": "2022-05-30T17:50:53.684989",
     "exception": false,
     "start_time": "2022-05-30T17:50:45.866870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 458913 train targets\n",
      "There are 190 train dataframe columns\n",
      "There are 458913 unique customers in train.\n"
     ]
    }
   ],
   "source": [
    "import cupy, cudf # GPU LIBRARIES\n",
    "import numpy as np, pandas as pd # CPU LIBRARIES\n",
    "import matplotlib.pyplot as plt, gc\n",
    "\n",
    "if PROCESS_DATA:\n",
    "    # LOAD TARGETS\n",
    "    targets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    targets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "    print(f'There are {targets.shape[0]} train targets')\n",
    "    \n",
    "    # GET TRAIN COLUMN NAMES\n",
    "    train = cudf.read_csv('../input/amex-default-prediction/train_data.csv', nrows=1)\n",
    "    T_COLS = train.columns\n",
    "    print(f'There are {len(T_COLS)} train dataframe columns')\n",
    "    \n",
    "    # GET TRAIN CUSTOMER NAMES (use pandas to avoid memory error)\n",
    "    if PATH_TO_CUSTOMER_HASHES:\n",
    "        train = cudf.read_parquet(f'{PATH_TO_CUSTOMER_HASHES}train_customer_hashes.pqt')\n",
    "    else:\n",
    "        train = pd.read_csv('/raid/Kaggle/amex/train_data.csv', usecols=['customer_ID'])\n",
    "        train['customer_ID'] = train['customer_ID'].apply(lambda x: int(x[-16:],16) ).astype('int64')\n",
    "    customers = train.drop_duplicates().sort_index().values.flatten()\n",
    "    print(f'There are {len(customers)} unique customers in train.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d0668e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-30T17:50:53.697661Z",
     "iopub.status.busy": "2022-05-30T17:50:53.697327Z",
     "iopub.status.idle": "2022-05-30T17:50:54.260165Z",
     "shell.execute_reply": "2022-05-30T17:50:54.259349Z"
    },
    "papermill": {
     "duration": 0.571351,
     "end_time": "2022-05-30T17:50:54.262156",
     "exception": false,
     "start_time": "2022-05-30T17:50:53.690805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will split train data into 10 separate files.\n",
      "There will be 45891 customers in each file (except the last file).\n",
      "Below are number of rows in each file:\n",
      "[553403, 552855, 554025, 554330, 552004, 552378, 552822, 553151, 553493, 552990]\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE SIZE OF EACH SEPARATE FILE\n",
    "def get_rows(customers, train, NUM_FILES = 10, verbose = ''):\n",
    "    chunk = len(customers)//NUM_FILES\n",
    "    if verbose != '':\n",
    "        print(f'We will split {verbose} data into {NUM_FILES} separate files.')\n",
    "        print(f'There will be {chunk} customers in each file (except the last file).')\n",
    "        print('Below are number of rows in each file:')\n",
    "    rows = []\n",
    "\n",
    "    for k in range(NUM_FILES):\n",
    "        if k==NUM_FILES-1: cc = customers[k*chunk:]\n",
    "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
    "        s = train.loc[train.customer_ID.isin(cc)].shape[0]\n",
    "        rows.append(s)\n",
    "    if verbose != '': print( rows )\n",
    "    return rows\n",
    "\n",
    "if PROCESS_DATA:\n",
    "    NUM_FILES = 10\n",
    "    rows = get_rows(customers, train, NUM_FILES = NUM_FILES, verbose = 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5137e88",
   "metadata": {
    "papermill": {
     "duration": 0.005592,
     "end_time": "2022-05-30T17:50:54.273574",
     "exception": false,
     "start_time": "2022-05-30T17:50:54.267982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess and Feature Engineering\n",
    "The function below processes the data. Discussions describing the process are [here][1] and [here][2]. Currently the code below uses [RAPIDS][3] and GPU to\n",
    "* Reduces memory usage of customer_ID column by converting to int64\n",
    "* Reduces memory usage of date time column (then deletes the column).\n",
    "* We fill NANs\n",
    "* Label encodes the categorical columns\n",
    "* We reduce memory usage dtypes of columns\n",
    "* Converts every customer into a 3D array with sequence length 13 and feature length 188\n",
    "\n",
    "To improve this model, try adding new feautures. The columns have been rearanged to have the 11 categorical features first. This makes building the TensorFlow model later easier. We can also try adding Standard Scaler. Currently the data is being used without scaling from the original Kaggle train data. \n",
    "\n",
    "[1]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/327828\n",
    "[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328054\n",
    "[3]: https://rapids.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3be282e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T17:50:54.286453Z",
     "iopub.status.busy": "2022-05-30T17:50:54.286007Z",
     "iopub.status.idle": "2022-05-30T17:50:54.303731Z",
     "shell.execute_reply": "2022-05-30T17:50:54.302865Z"
    },
    "papermill": {
     "duration": 0.026423,
     "end_time": "2022-05-30T17:50:54.305611",
     "exception": false,
     "start_time": "2022-05-30T17:50:54.279188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineer(train, PAD_CUSTOMER_TO_13_ROWS = True, targets = None):\n",
    "        \n",
    "    # REDUCE STRING COLUMNS \n",
    "    # from 64 bytes to 8 bytes, and 10 bytes to 3 bytes respectively\n",
    "    train['customer_ID'] = train['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "    train.S_2 = cudf.to_datetime( train.S_2 )\n",
    "    train['year'] = (train.S_2.dt.year-2000).astype('int8')\n",
    "    train['month'] = (train.S_2.dt.month).astype('int8')\n",
    "    train['day'] = (train.S_2.dt.day).astype('int8')\n",
    "    del train['S_2']\n",
    "        \n",
    "    # LABEL ENCODE CAT COLUMNS (and reduce to 1 byte)\n",
    "    # with 0: padding, 1: nan, 2,3,4,etc: values\n",
    "    d_63_map = {'CL':2, 'CO':3, 'CR':4, 'XL':5, 'XM':6, 'XZ':7}\n",
    "    train['D_63'] = train.D_63.map(d_63_map).fillna(1).astype('int8')\n",
    "\n",
    "    d_64_map = {'-1':2,'O':3, 'R':4, 'U':5}\n",
    "    train['D_64'] = train.D_64.map(d_64_map).fillna(1).astype('int8')\n",
    "    \n",
    "    CATS = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_66', 'D_68']\n",
    "    OFFSETS = [2,1,2,2,3,2,3,2,2] #2 minus minimal value in full train csv\n",
    "    # then 0 will be padding, 1 will be NAN, 2,3,4,etc will be values\n",
    "    for c,s in zip(CATS,OFFSETS):\n",
    "        train[c] = train[c] + s\n",
    "        train[c] = train[c].fillna(1).astype('int8')\n",
    "    CATS += ['D_63','D_64']\n",
    "    \n",
    "    # ADD NEW FEATURES HERE\n",
    "    # EXAMPLE: train['feature_189'] = etc etc etc\n",
    "    # EXAMPLE: train['feature_190'] = etc etc etc\n",
    "    # IF CATEGORICAL, THEN ADD TO CATS WITH: CATS += ['feaure_190'] etc etc etc\n",
    "    \n",
    "    # REDUCE MEMORY DTYPE\n",
    "    SKIP = ['customer_ID','year','month','day']\n",
    "    for c in train.columns:\n",
    "        if c in SKIP: continue\n",
    "        if str( train[c].dtype )=='int64':\n",
    "            train[c] = train[c].astype('int32')\n",
    "        if str( train[c].dtype )=='float64':\n",
    "            train[c] = train[c].astype('float32')\n",
    "            \n",
    "    # PAD ROWS SO EACH CUSTOMER HAS 13 ROWS\n",
    "    if PAD_CUSTOMER_TO_13_ROWS:\n",
    "        tmp = train[['customer_ID']].groupby('customer_ID').customer_ID.agg('count')\n",
    "        more = cupy.array([],dtype='int64') \n",
    "        for j in range(1,13):\n",
    "            i = tmp.loc[tmp==j].index.values\n",
    "            more = cupy.concatenate([more,cupy.repeat(i,13-j)])\n",
    "        df = train.iloc[:len(more)].copy().fillna(0)\n",
    "        df = df * 0 - 1 #pad numerical columns with -1\n",
    "        df[CATS] = (df[CATS] * 0).astype('int8') #pad categorical columns with 0\n",
    "        df['customer_ID'] = more\n",
    "        train = cudf.concat([train,df],axis=0,ignore_index=True)\n",
    "        \n",
    "    # ADD TARGETS (and reduce to 1 byte)\n",
    "    if targets is not None:\n",
    "        train = train.merge(targets,on='customer_ID',how='left')\n",
    "        train.target = train.target.astype('int8')\n",
    "        \n",
    "    # FILL NAN\n",
    "    train = train.fillna(-0.5) #this applies to numerical columns\n",
    "    \n",
    "    # SORT BY CUSTOMER THEN DATE\n",
    "    train = train.sort_values(['customer_ID','year','month','day']).reset_index(drop=True)\n",
    "    train = train.drop(['year','month','day'],axis=1)\n",
    "    \n",
    "    # REARRANGE COLUMNS WITH 11 CATS FIRST\n",
    "    COLS = list(train.columns[1:])\n",
    "    COLS = ['customer_ID'] + CATS + [c for c in COLS if c not in CATS]\n",
    "    train = train[COLS]\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f56871",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-30T17:50:54.318071Z",
     "iopub.status.busy": "2022-05-30T17:50:54.317812Z",
     "iopub.status.idle": "2022-05-30T17:57:47.846153Z",
     "shell.execute_reply": "2022-05-30T17:57:47.844395Z"
    },
    "papermill": {
     "duration": 413.540875,
     "end_time": "2022-05-30T17:57:47.852255",
     "exception": false,
     "start_time": "2022-05-30T17:50:54.311380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_File_1 has 45891 customers and shape (596583, 190)\n",
      "Train_File_2 has 45891 customers and shape (596583, 190)\n",
      "Train_File_3 has 45891 customers and shape (596583, 190)\n",
      "Train_File_4 has 45891 customers and shape (596583, 190)\n",
      "Train_File_5 has 45891 customers and shape (596583, 190)\n",
      "Train_File_6 has 45891 customers and shape (596583, 190)\n",
      "Train_File_7 has 45891 customers and shape (596583, 190)\n",
      "Train_File_8 has 45891 customers and shape (596583, 190)\n",
      "Train_File_9 has 45891 customers and shape (596583, 190)\n",
      "Train_File_10 has 45894 customers and shape (596622, 190)\n"
     ]
    }
   ],
   "source": [
    "if PROCESS_DATA:\n",
    "    # CREATE PROCESSED TRAIN FILES AND SAVE TO DISK        \n",
    "    for k in range(NUM_FILES):\n",
    "\n",
    "        # READ CHUNK OF TRAIN CSV FILE\n",
    "        skip = int(np.sum( rows[:k] ) + 1) #the plus one is for skipping header\n",
    "        train = cudf.read_csv('../input/amex-default-prediction/train_data.csv', nrows=rows[k], \n",
    "                              skiprows=skip, header=None, names=T_COLS)\n",
    "\n",
    "        # FEATURE ENGINEER DATAFRAME\n",
    "        train = feature_engineer(train, targets = targets)\n",
    "\n",
    "        # SAVE FILES\n",
    "        print(f'Train_File_{k+1} has {train.customer_ID.nunique()} customers and shape',train.shape)\n",
    "        tar = train[['customer_ID','target']].drop_duplicates().sort_index()\n",
    "        if not os.path.exists(PATH_TO_DATA): os.makedirs(PATH_TO_DATA)\n",
    "        tar.to_parquet(f'{PATH_TO_DATA}targets_{k+1}.pqt',index=False)\n",
    "        data = train.iloc[:,1:-1].values.reshape((-1,13,188))\n",
    "        cupy.save(f'{PATH_TO_DATA}data_{k+1}',data.astype('float32'))\n",
    "\n",
    "    # CLEAN MEMORY\n",
    "    del train, tar, data\n",
    "    del targets\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b1e0b",
   "metadata": {
    "papermill": {
     "duration": 0.010301,
     "end_time": "2022-05-30T17:57:47.880213",
     "exception": false,
     "start_time": "2022-05-30T17:57:47.869912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Model\n",
    "We will just input the sequence data into a basic GRU. We will follow that we two dense layers and finally a sigmoid output to predict default. Try improving the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d4bf506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T17:57:47.902788Z",
     "iopub.status.busy": "2022-05-30T17:57:47.902020Z",
     "iopub.status.idle": "2022-05-30T17:57:47.923421Z",
     "shell.execute_reply": "2022-05-30T17:57:47.922481Z"
    },
    "papermill": {
     "duration": 0.0383,
     "end_time": "2022-05-30T17:57:47.925787",
     "exception": false,
     "start_time": "2022-05-30T17:57:47.887487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SIMPLE GRU MODEL\n",
    "def build_model():\n",
    "    \n",
    "    # INPUT - FIRST 11 COLUMNS ARE CAT, NEXT 177 ARE NUMERIC\n",
    "    inp = tf.keras.Input(shape=(13,188))\n",
    "    embeddings = []\n",
    "    for k in range(11):\n",
    "        emb = tf.keras.layers.Embedding(10,4)\n",
    "        embeddings.append( emb(inp[:,:,k]) )\n",
    "    x = tf.keras.layers.Concatenate()([inp[:,:,11:]]+embeddings)\n",
    "    \n",
    "    # SIMPLE RNN BACKBONE\n",
    "    x = tf.keras.layers.GRU(units=128, return_sequences=False)(x)\n",
    "    x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "    \n",
    "    # OUTPUT\n",
    "    x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    # COMPILE MODEL\n",
    "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    model.compile(loss=loss, optimizer = opt)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae01815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T17:57:47.948280Z",
     "iopub.status.busy": "2022-05-30T17:57:47.947987Z",
     "iopub.status.idle": "2022-05-30T17:57:47.954091Z",
     "shell.execute_reply": "2022-05-30T17:57:47.953127Z"
    },
    "papermill": {
     "duration": 0.020396,
     "end_time": "2022-05-30T17:57:47.956835",
     "exception": false,
     "start_time": "2022-05-30T17:57:47.936439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CUSTOM LEARNING SCHEUDLE\n",
    "def lrfn(epoch):\n",
    "    lr = [1e-3]*5 + [1e-4]*2 + [1e-5]*1\n",
    "    return lr[epoch]\n",
    "LR = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da81b128",
   "metadata": {
    "papermill": {
     "duration": 0.010566,
     "end_time": "2022-05-30T17:57:47.978369",
     "exception": false,
     "start_time": "2022-05-30T17:57:47.967803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Competition Metric Code\n",
    "The code below is from Konstantin Yakovlev's discussion post [here][1]\n",
    "\n",
    "[1]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3727560d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T17:57:48.001055Z",
     "iopub.status.busy": "2022-05-30T17:57:48.000587Z",
     "iopub.status.idle": "2022-05-30T17:57:48.014505Z",
     "shell.execute_reply": "2022-05-30T17:57:48.013674Z"
    },
    "papermill": {
     "duration": 0.027183,
     "end_time": "2022-05-30T17:57:48.016224",
     "exception": false,
     "start_time": "2022-05-30T17:57:47.989041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COMPETITION METRIC FROM Konstantin Yakovlev\n",
    "# https://www.kaggle.com/kyakovlev\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n",
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2f762",
   "metadata": {
    "papermill": {
     "duration": 0.01094,
     "end_time": "2022-05-30T17:57:48.037438",
     "exception": false,
     "start_time": "2022-05-30T17:57:48.026498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Model\n",
    "We train 5 folds for 8 epochs each. We save the 5 fold models for test inference later. If you only want to infer without training, then set variable `TRAIN_MODEL = False` in the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2c0889",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-30T17:57:48.061876Z",
     "iopub.status.busy": "2022-05-30T17:57:48.061361Z",
     "iopub.status.idle": "2022-05-30T18:07:02.852468Z",
     "shell.execute_reply": "2022-05-30T18:07:02.851377Z"
    },
    "papermill": {
     "duration": 554.807567,
     "end_time": "2022-05-30T18:07:02.856272",
     "exception": false,
     "start_time": "2022-05-30T17:57:48.048705",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1 with valid files [1, 2]\n",
      "### Training data shapes (367131, 13, 188) (367131,)\n",
      "### Validation data shapes (91782, 13, 188) (91782,)\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 17:58:15.708431: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3589072656 exceeds 10% of free system memory.\n",
      "2022-05-30 17:58:19.930114: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 3589072656 exceeds 10% of free system memory.\n",
      "2022-05-30 17:58:22.681200: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 17:58:26.193627: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n",
      "2022-05-30 17:58:36.542571: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 897260832 exceeds 10% of free system memory.\n",
      "2022-05-30 17:58:37.736819: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 897260832 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718/718 - 17s - loss: 0.2380 - val_loss: 0.2303\n",
      "Epoch 2/8\n",
      "718/718 - 9s - loss: 0.2269 - val_loss: 0.2285\n",
      "Epoch 3/8\n",
      "718/718 - 10s - loss: 0.2237 - val_loss: 0.2276\n",
      "Epoch 4/8\n",
      "718/718 - 9s - loss: 0.2209 - val_loss: 0.2255\n",
      "Epoch 5/8\n",
      "718/718 - 9s - loss: 0.2187 - val_loss: 0.2249\n",
      "Epoch 6/8\n",
      "718/718 - 9s - loss: 0.2125 - val_loss: 0.2228\n",
      "Epoch 7/8\n",
      "718/718 - 9s - loss: 0.2112 - val_loss: 0.2227\n",
      "Epoch 8/8\n",
      "718/718 - 9s - loss: 0.2099 - val_loss: 0.2227\n",
      "Inferring validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 17:59:47.144854: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 897260832 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 1s\n",
      "\n",
      "Fold 1 CV= 0.78799191353603\n",
      "\n",
      "#########################\n",
      "### Fold 2 with valid files [3, 4]\n",
      "### Training data shapes (367131, 13, 188) (367131,)\n",
      "### Validation data shapes (91782, 13, 188) (91782,)\n",
      "#########################\n",
      "Epoch 1/8\n",
      "718/718 - 14s - loss: 0.2415 - val_loss: 0.2318\n",
      "Epoch 2/8\n",
      "718/718 - 9s - loss: 0.2271 - val_loss: 0.2285\n",
      "Epoch 3/8\n",
      "718/718 - 9s - loss: 0.2238 - val_loss: 0.2267\n",
      "Epoch 4/8\n",
      "718/718 - 9s - loss: 0.2213 - val_loss: 0.2260\n",
      "Epoch 5/8\n",
      "718/718 - 10s - loss: 0.2189 - val_loss: 0.2266\n",
      "Epoch 6/8\n",
      "718/718 - 9s - loss: 0.2129 - val_loss: 0.2230\n",
      "Epoch 7/8\n",
      "718/718 - 9s - loss: 0.2117 - val_loss: 0.2229\n",
      "Epoch 8/8\n",
      "718/718 - 10s - loss: 0.2105 - val_loss: 0.2227\n",
      "Inferring validation data...\n",
      "180/180 - 1s\n",
      "\n",
      "Fold 2 CV= 0.7838323128060836\n",
      "\n",
      "#########################\n",
      "### Fold 3 with valid files [5, 6]\n",
      "### Training data shapes (367131, 13, 188) (367131,)\n",
      "### Validation data shapes (91782, 13, 188) (91782,)\n",
      "#########################\n",
      "Epoch 1/8\n",
      "718/718 - 14s - loss: 0.2414 - val_loss: 0.2303\n",
      "Epoch 2/8\n",
      "718/718 - 9s - loss: 0.2276 - val_loss: 0.2258\n",
      "Epoch 3/8\n",
      "718/718 - 9s - loss: 0.2242 - val_loss: 0.2242\n",
      "Epoch 4/8\n",
      "718/718 - 9s - loss: 0.2216 - val_loss: 0.2243\n",
      "Epoch 5/8\n",
      "718/718 - 10s - loss: 0.2191 - val_loss: 0.2238\n",
      "Epoch 6/8\n",
      "718/718 - 10s - loss: 0.2131 - val_loss: 0.2210\n",
      "Epoch 7/8\n",
      "718/718 - 9s - loss: 0.2119 - val_loss: 0.2215\n",
      "Epoch 8/8\n",
      "718/718 - 10s - loss: 0.2107 - val_loss: 0.2211\n",
      "Inferring validation data...\n",
      "180/180 - 1s\n",
      "\n",
      "Fold 3 CV= 0.7859509438158216\n",
      "\n",
      "#########################\n",
      "### Fold 4 with valid files [7, 8]\n",
      "### Training data shapes (367131, 13, 188) (367131,)\n",
      "### Validation data shapes (91782, 13, 188) (91782,)\n",
      "#########################\n",
      "Epoch 1/8\n",
      "718/718 - 14s - loss: 0.2397 - val_loss: 0.2352\n",
      "Epoch 2/8\n",
      "718/718 - 9s - loss: 0.2274 - val_loss: 0.2315\n",
      "Epoch 3/8\n",
      "718/718 - 9s - loss: 0.2244 - val_loss: 0.2226\n",
      "Epoch 4/8\n",
      "718/718 - 10s - loss: 0.2219 - val_loss: 0.2226\n",
      "Epoch 5/8\n",
      "718/718 - 9s - loss: 0.2196 - val_loss: 0.2225\n",
      "Epoch 6/8\n",
      "718/718 - 9s - loss: 0.2136 - val_loss: 0.2193\n",
      "Epoch 7/8\n",
      "718/718 - 10s - loss: 0.2124 - val_loss: 0.2191\n",
      "Epoch 8/8\n",
      "718/718 - 10s - loss: 0.2112 - val_loss: 0.2190\n",
      "Inferring validation data...\n",
      "180/180 - 1s\n",
      "\n",
      "Fold 4 CV= 0.787544771437652\n",
      "\n",
      "#########################\n",
      "### Fold 5 with valid files [9, 10]\n",
      "### Training data shapes (367128, 13, 188) (367128,)\n",
      "### Validation data shapes (91785, 13, 188) (91785,)\n",
      "#########################\n",
      "Epoch 1/8\n",
      "718/718 - 14s - loss: 0.2397 - val_loss: 0.2400\n",
      "Epoch 2/8\n",
      "718/718 - 9s - loss: 0.2281 - val_loss: 0.2240\n",
      "Epoch 3/8\n",
      "718/718 - 10s - loss: 0.2245 - val_loss: 0.2237\n",
      "Epoch 4/8\n",
      "718/718 - 9s - loss: 0.2220 - val_loss: 0.2225\n",
      "Epoch 5/8\n",
      "718/718 - 9s - loss: 0.2199 - val_loss: 0.2212\n",
      "Epoch 6/8\n",
      "718/718 - 10s - loss: 0.2138 - val_loss: 0.2195\n",
      "Epoch 7/8\n",
      "718/718 - 9s - loss: 0.2124 - val_loss: 0.2197\n",
      "Epoch 8/8\n",
      "718/718 - 10s - loss: 0.2112 - val_loss: 0.2195\n",
      "Inferring validation data...\n",
      "180/180 - 1s\n",
      "\n",
      "Fold 5 CV= 0.7887652111643455\n",
      "\n",
      "#########################\n",
      "Overall CV = 0.7866580398847685\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_MODEL:\n",
    "    # SAVE TRUE AND OOF\n",
    "    true = np.array([])\n",
    "    oof = np.array([])\n",
    "    VERBOSE = 2 # use 1 for interactive \n",
    "\n",
    "    for fold in range(5):\n",
    "\n",
    "        # INDICES OF TRAIN AND VALID FOLDS\n",
    "        valid_idx = [2*fold+1, 2*fold+2]\n",
    "        train_idx = [x for x in [1,2,3,4,5,6,7,8,9,10] if x not in valid_idx]\n",
    "\n",
    "        print('#'*25)\n",
    "        print(f'### Fold {fold+1} with valid files', valid_idx)\n",
    "\n",
    "        # READ TRAIN DATA FROM DISK\n",
    "        X_train = []; y_train = []\n",
    "        for k in train_idx:\n",
    "            X_train.append( np.load(f'{PATH_TO_DATA}data_{k}.npy'))\n",
    "            y_train.append( pd.read_parquet(f'{PATH_TO_DATA}targets_{k}.pqt') )\n",
    "        X_train = np.concatenate(X_train,axis=0)\n",
    "        y_train = pd.concat(y_train).target.values\n",
    "        print('### Training data shapes', X_train.shape, y_train.shape)\n",
    "\n",
    "        # READ VALID DATA FROM DISK\n",
    "        X_valid = []; y_valid = []\n",
    "        for k in valid_idx:\n",
    "            X_valid.append( np.load(f'{PATH_TO_DATA}data_{k}.npy'))\n",
    "            y_valid.append( pd.read_parquet(f'{PATH_TO_DATA}targets_{k}.pqt') )\n",
    "        X_valid = np.concatenate(X_valid,axis=0)\n",
    "        y_valid = pd.concat(y_valid).target.values\n",
    "        print('### Validation data shapes', X_valid.shape, y_valid.shape)\n",
    "        print('#'*25)\n",
    "\n",
    "        # BUILD AND TRAIN MODEL\n",
    "        K.clear_session()\n",
    "        model = build_model()\n",
    "        h = model.fit(X_train,y_train, \n",
    "                      validation_data = (X_valid,y_valid),\n",
    "                      batch_size=512, epochs=8, verbose=VERBOSE,\n",
    "                      callbacks = [LR])\n",
    "        if not os.path.exists(PATH_TO_MODEL): os.makedirs(PATH_TO_MODEL)\n",
    "        model.save_weights(f'{PATH_TO_MODEL}gru_fold_{fold+1}.h5')\n",
    "\n",
    "        # INFER VALID DATA\n",
    "        print('Inferring validation data...')\n",
    "        p = model.predict(X_valid, batch_size=512, verbose=VERBOSE).flatten()\n",
    "\n",
    "        print()\n",
    "        print(f'Fold {fold+1} CV=', amex_metric_mod(y_valid, p) )\n",
    "        print()\n",
    "        true = np.concatenate([true, y_valid])\n",
    "        oof = np.concatenate([oof, p])\n",
    "        \n",
    "        # CLEAN MEMORY\n",
    "        del model, X_train, y_train, X_valid, y_valid, p\n",
    "        gc.collect()\n",
    "\n",
    "    # PRINT OVERALL RESULTS\n",
    "    print('#'*25)\n",
    "    print(f'Overall CV =', amex_metric_mod(true, oof) )\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb3a74",
   "metadata": {
    "papermill": {
     "duration": 0.012615,
     "end_time": "2022-05-30T18:07:02.883303",
     "exception": false,
     "start_time": "2022-05-30T18:07:02.870688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Process Test Data\n",
    "We process the test data in the same way as train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18f3b0dc",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2022-05-30T18:07:02.911274Z",
     "iopub.status.busy": "2022-05-30T18:07:02.910440Z",
     "iopub.status.idle": "2022-05-30T18:07:04.289141Z",
     "shell.execute_reply": "2022-05-30T18:07:04.288190Z"
    },
    "papermill": {
     "duration": 1.394878,
     "end_time": "2022-05-30T18:07:04.291019",
     "exception": false,
     "start_time": "2022-05-30T18:07:02.896141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 190 test dataframe columns\n",
      "There are 924621 unique customers in test.\n"
     ]
    }
   ],
   "source": [
    "if PROCESS_DATA:\n",
    "    # GET TEST COLUMN NAMES\n",
    "    test = cudf.read_csv('../input/amex-default-prediction/test_data.csv', nrows=1)\n",
    "    T_COLS = test.columns\n",
    "    print(f'There are {len(T_COLS)} test dataframe columns')\n",
    "    \n",
    "    # GET TEST CUSTOMER NAMES (use pandas to avoid memory error)\n",
    "    if PATH_TO_CUSTOMER_HASHES:\n",
    "        test = cudf.read_parquet(f'{PATH_TO_CUSTOMER_HASHES}test_customer_hashes.pqt')\n",
    "    else:\n",
    "        test = pd.read_csv('/raid/Kaggle/amex/test_data.csv', usecols=['customer_ID'])\n",
    "        test['customer_ID'] = test['customer_ID'].apply(lambda x: int(x[-16:],16) ).astype('int64')\n",
    "    customers = test.drop_duplicates().sort_index().values.flatten()\n",
    "    print(f'There are {len(customers)} unique customers in test.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b2df580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T18:07:04.319074Z",
     "iopub.status.busy": "2022-05-30T18:07:04.318788Z",
     "iopub.status.idle": "2022-05-30T18:07:06.231796Z",
     "shell.execute_reply": "2022-05-30T18:07:06.229983Z"
    },
    "papermill": {
     "duration": 1.929687,
     "end_time": "2022-05-30T18:07:06.233797",
     "exception": false,
     "start_time": "2022-05-30T18:07:04.304110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will split test data into 20 separate files.\n",
      "There will be 46231 customers in each file (except the last file).\n",
      "Below are number of rows in each file:\n",
      "[567933, 568482, 569369, 567886, 567539, 568041, 568138, 567596, 568543, 567539, 568421, 568745, 568279, 568333, 568327, 568901, 568300, 568001, 567372, 568017]\n"
     ]
    }
   ],
   "source": [
    "NUM_FILES = 20\n",
    "if PROCESS_DATA:\n",
    "    # CALCULATE SIZE OF EACH SEPARATE FILE\n",
    "    rows = get_rows(customers, test, NUM_FILES = NUM_FILES, verbose = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9cf4720",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-30T18:07:06.261968Z",
     "iopub.status.busy": "2022-05-30T18:07:06.261649Z",
     "iopub.status.idle": "2022-05-30T19:05:45.505756Z",
     "shell.execute_reply": "2022-05-30T19:05:45.504898Z"
    },
    "papermill": {
     "duration": 3519.263224,
     "end_time": "2022-05-30T19:05:45.510635",
     "exception": false,
     "start_time": "2022-05-30T18:07:06.247411",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_File_1 has 46231 customers and shape (601003, 189)\n",
      "Test_File_2 has 46231 customers and shape (601003, 189)\n",
      "Test_File_3 has 46231 customers and shape (601003, 189)\n",
      "Test_File_4 has 46231 customers and shape (601003, 189)\n",
      "Test_File_5 has 46231 customers and shape (601003, 189)\n",
      "Test_File_6 has 46231 customers and shape (601003, 189)\n",
      "Test_File_7 has 46231 customers and shape (601003, 189)\n",
      "Test_File_8 has 46231 customers and shape (601003, 189)\n",
      "Test_File_9 has 46231 customers and shape (601003, 189)\n",
      "Test_File_10 has 46231 customers and shape (601003, 189)\n",
      "Test_File_11 has 46231 customers and shape (601003, 189)\n",
      "Test_File_12 has 46231 customers and shape (601003, 189)\n",
      "Test_File_13 has 46231 customers and shape (601003, 189)\n",
      "Test_File_14 has 46231 customers and shape (601003, 189)\n",
      "Test_File_15 has 46231 customers and shape (601003, 189)\n",
      "Test_File_16 has 46231 customers and shape (601003, 189)\n",
      "Test_File_17 has 46231 customers and shape (601003, 189)\n",
      "Test_File_18 has 46231 customers and shape (601003, 189)\n",
      "Test_File_19 has 46231 customers and shape (601003, 189)\n",
      "Test_File_20 has 46232 customers and shape (601016, 189)\n"
     ]
    }
   ],
   "source": [
    "if PROCESS_DATA:\n",
    "    # SAVE TEST CUSTOMERS INDEX\n",
    "    test_customer_hashes = cupy.array([],dtype='int64')\n",
    "    \n",
    "    # CREATE PROCESSED TEST FILES AND SAVE TO DISK\n",
    "    for k in range(NUM_FILES):\n",
    "\n",
    "        # READ CHUNK OF TEST CSV FILE\n",
    "        skip = int(np.sum( rows[:k] ) + 1) #the plus one is for skipping header\n",
    "        test = cudf.read_csv('../input/amex-default-prediction/test_data.csv', nrows=rows[k], \n",
    "                              skiprows=skip, header=None, names=T_COLS)\n",
    "\n",
    "        # FEATURE ENGINEER DATAFRAME\n",
    "        test = feature_engineer(test, targets = None)\n",
    "        \n",
    "        # SAVE TEST CUSTOMERS INDEX\n",
    "        cust = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n",
    "        test_customer_hashes = cupy.concatenate([test_customer_hashes,cust])\n",
    "\n",
    "        # SAVE FILES\n",
    "        print(f'Test_File_{k+1} has {test.customer_ID.nunique()} customers and shape',test.shape)\n",
    "        data = test.iloc[:,1:].values.reshape((-1,13,188))\n",
    "        cupy.save(f'{PATH_TO_DATA}test_data_{k+1}',data.astype('float32'))\n",
    "        \n",
    "    # SAVE CUSTOMER INDEX OF ALL TEST FILES\n",
    "    cupy.save(f'{PATH_TO_DATA}test_hashes_data', test_customer_hashes)\n",
    "\n",
    "    # CLEAN MEMORY\n",
    "    del test, data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119200f",
   "metadata": {
    "papermill": {
     "duration": 0.014013,
     "end_time": "2022-05-30T19:05:45.539751",
     "exception": false,
     "start_time": "2022-05-30T19:05:45.525738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer Test Data\n",
    "We infer the test data from our saved fold models. If you don't wish to infer test but you only want your notebook to compute a validation score to evaluate model changes, then set variable `INFER_TEST = False` in the beginning of this notebook. Also if you wish to infer from previously trained models, then add the path to the Kaggle dataset in the variable `PATH_TO_MODEL` in the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "950e8a9f",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-05-30T19:05:45.569055Z",
     "iopub.status.busy": "2022-05-30T19:05:45.568768Z",
     "iopub.status.idle": "2022-05-30T19:08:46.787919Z",
     "shell.execute_reply": "2022-05-30T19:08:46.787000Z"
    },
    "papermill": {
     "duration": 181.236439,
     "end_time": "2022-05-30T19:08:46.790246",
     "exception": false,
     "start_time": "2022-05-30T19:05:45.553807",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring Test_File_1\n",
      "Inferring Test_File_2\n",
      "Inferring Test_File_3\n",
      "Inferring Test_File_4\n",
      "Inferring Test_File_5\n",
      "Inferring Test_File_6\n",
      "Inferring Test_File_7\n",
      "Inferring Test_File_8\n",
      "Inferring Test_File_9\n",
      "Inferring Test_File_10\n",
      "Inferring Test_File_11\n",
      "Inferring Test_File_12\n",
      "Inferring Test_File_13\n",
      "Inferring Test_File_14\n",
      "Inferring Test_File_15\n",
      "Inferring Test_File_16\n",
      "Inferring Test_File_17\n",
      "Inferring Test_File_18\n",
      "Inferring Test_File_19\n",
      "Inferring Test_File_20\n"
     ]
    }
   ],
   "source": [
    "if INFER_TEST:\n",
    "    # INFER TEST DATA\n",
    "    start = 0; end = 0\n",
    "    sub = cudf.read_csv('../input/amex-default-prediction/sample_submission.csv')\n",
    "    \n",
    "    # REARANGE SUB ROWS TO MATCH PROCESSED TEST FILES\n",
    "    sub['hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "    test_hash_index = cupy.load(f'{PATH_TO_DATA}test_hashes_data.npy')\n",
    "    sub = sub.set_index('hash').loc[test_hash_index].reset_index(drop=True)\n",
    "    \n",
    "    for k in range(NUM_FILES):\n",
    "        # BUILD MODEL\n",
    "        K.clear_session()\n",
    "        model = build_model()\n",
    "        \n",
    "        # LOAD TEST DATA\n",
    "        print(f'Inferring Test_File_{k+1}')\n",
    "        X_test = np.load(f'{PATH_TO_DATA}test_data_{k+1}.npy')\n",
    "        end = start + X_test.shape[0]\n",
    "\n",
    "        # INFER 5 FOLD MODELS\n",
    "        model.load_weights(f'{PATH_TO_MODEL}gru_fold_1.h5')\n",
    "        p = model.predict(X_test, batch_size=512, verbose=0).flatten() \n",
    "        for j in range(1,5):\n",
    "            model.load_weights(f'{PATH_TO_MODEL}gru_fold_{j+1}.h5')\n",
    "            p += model.predict(X_test, batch_size=512, verbose=0).flatten()\n",
    "        p /= 5.0\n",
    "\n",
    "        # SAVE TEST PREDICTIONS\n",
    "        sub.loc[start:end-1,'prediction'] = p\n",
    "        start = end\n",
    "        \n",
    "        # CLEAN MEMORY\n",
    "        del model, X_test, p\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58004fff",
   "metadata": {
    "papermill": {
     "duration": 0.015373,
     "end_time": "2022-05-30T19:08:46.821435",
     "exception": false,
     "start_time": "2022-05-30T19:08:46.806062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "452274b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T19:08:46.854738Z",
     "iopub.status.busy": "2022-05-30T19:08:46.854360Z",
     "iopub.status.idle": "2022-05-30T19:08:47.093150Z",
     "shell.execute_reply": "2022-05-30T19:08:47.092353Z"
    },
    "papermill": {
     "duration": 0.258173,
     "end_time": "2022-05-30T19:08:47.095245",
     "exception": false,
     "start_time": "2022-05-30T19:08:46.837072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file shape is (924621, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038be0571bd6b3776cb8512731968f4de302c811030124...</td>\n",
       "      <td>0.003422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0074a0233ef766b52884608cc8cf9098f59d885b5d59fc...</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>060b8b7f30f795a0e93995d45b29461ffa6ece0eeb5c3d...</td>\n",
       "      <td>0.102515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03a1d125bdd776000bf0b28238d0bea240ad581d332e70...</td>\n",
       "      <td>0.126610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0290f245dd35ba899af52316ccc62b2627e7ae18cd76a2...</td>\n",
       "      <td>0.330832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  prediction\n",
       "0  038be0571bd6b3776cb8512731968f4de302c811030124...    0.003422\n",
       "1  0074a0233ef766b52884608cc8cf9098f59d885b5d59fc...    0.000194\n",
       "2  060b8b7f30f795a0e93995d45b29461ffa6ece0eeb5c3d...    0.102515\n",
       "3  03a1d125bdd776000bf0b28238d0bea240ad581d332e70...    0.126610\n",
       "4  0290f245dd35ba899af52316ccc62b2627e7ae18cd76a2...    0.330832"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if INFER_TEST:\n",
    "    sub.to_csv('submission.csv',index=False)\n",
    "    print('Submission file shape is', sub.shape )\n",
    "    display( sub.head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbdaeeba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-30T19:08:47.128181Z",
     "iopub.status.busy": "2022-05-30T19:08:47.127796Z",
     "iopub.status.idle": "2022-05-30T19:08:47.925804Z",
     "shell.execute_reply": "2022-05-30T19:08:47.925053Z"
    },
    "papermill": {
     "duration": 0.816761,
     "end_time": "2022-05-30T19:08:47.927804",
     "exception": false,
     "start_time": "2022-05-30T19:08:47.111043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbdElEQVR4nO3df5TddX3n8efLxCBdhQQYEZNgqKbbjfQYcRbi2t0iKIToGnqKnLBWIic1WqHHrm5L0O6iKD2wexRli7hRUoK/QpZWydpgmgIu210DGSQGAmUZ+WESI4lJCLpUJPjaP76f2Mt4PzM3M5k7Seb1OOee+d735/P9fj7fBO5rvr9uZJuIiIh2XjTWE4iIiINXQiIiIqoSEhERUZWQiIiIqoRERERUJSQiIqIqIRExxiQ9LuktZfkjkr44zO1sknT6gZxbREIiDjmSftry+oWkf2x5/65hbO/bkv5gkPYZktwyxuOSloxsL9qz/ee2q3NpmdONkj45YN3X2v72aMwrxq+JYz2BiP1l+6X7liU9DvyB7b/rwtCTbe+V9EbgdkkbbH+rtYOkibb3dmEuEV2RI4k4bEh6kaQlkr4vaaeklZKOKW0vkfTlUn9K0npJx0u6EvjXwF+Uo4S/GGoc298BNgEnSzpd0hZJl0r6EfCXg82jzOXdkp4obR8dsA8fk/Tllve/Len/lDlvlvQeSYuBdwF/Wub8P0rf1tNWR0j6jKQfltdnJB1R2vbN+cOStkvaJumiljHnSXpQ0k8kbZX0H4b9lxKHvIREHE7+CDgX+B3glcBu4LrSthA4GpgOHAu8H/hH2x8F/hdwie2X2r5ksAHUeBPwWuC+Un4FcAzwKmDxYPOQNAu4Hnh3aTsWmFYZ61XAbcB/BXqA2cAG20uBrwD/ucz537ZZ/aPAnLLO64BTgT9raX9F+fOYCiwCrpM0pbTdALzP9suAk4E7BvszicNbQiIOJ+8HPmp7i+1ngY8B50maCDxH84H8GtvP277X9tP7uf0fA7uALwJLbN9e6r8ALrf9rO1/HGIe5wHftH1XafuPZf12/h3wd7a/Zvs52zttb+hwru8CrrC93fYO4OM0wbTPc6X9OdurgZ8C/7ylbZako2zvtv3dDseMw1CuScTh5FXA1yW1fug+DxwPfInmKGKFpMnAl2k+yJ/bj+0fV7nesMP2zzqcxyuBzfuKtv+fpJ2V8aYD39+P+bV6JfBEy/snSm2fnQP25Rlg37We36M56rhK0kaaQPzOMOcRh7gcScThZDNwju3JLa+X2N5afmP+uO1ZwL8C3g5cWNYb6VchD1y/Og9gG82HPwCSfo3mCKe2P6/ucMyBfkgTVvucWGpDsr3e9nzg5cA3gJWdrBeHp4REHE4+D1xZzuUjqUfS/LL8Zkm/JWkC8DTNKZV9v+k/Cfx6N+YB3AK8vVyQngRcQf3/w68Ab5F0vqSJko6VNLvDOX8N+LMy9nHAf6I5ehqUpEmS3iXp6HKU9TT102ExDiQk4nDyWWAV8LeSfgKsA04rba+g+YB+GngI+J80p6D2rXeepN2Srh3NedjeBFwMfJXmqGI3sKXdRmz/AJgHfJjmWsgGmovQ0FxcnlXuevpGm9U/CfQBG4H7ge+WWifeDTwu6Wma6yv7/exJHD6Uf3QoIiJqciQRERFVHYeEpAmS7pP0zfL+JEl3S+qXdHM5v7rvIZ6bS/1uSTNatnFZqT8s6eyW+txS61fL1x3UxoiIiO7YnyOJD9Kcy93nauAa26+hOa+6qNQXAbtL/ZrSb99DRAtoHkKaC3yuBM8EmgeNzgFmAReUvoONERERXdBRSEiaBryN5iEiJAk4g+ZCIMBymidMAeaX95T2M0v/+cCK8sDRY0A/zVOgpwL9th+1/XNgBTB/iDEiIqILOn2Y7jPAnwIvK++PBZ5qeRhnC83j/ZSfmwHKl6HtKf2n0tzlQZt1Ng+onzbEGFXHHXecZ8yY0eFuRUQEwL333vtj2z0D60OGhKS3A9tt36uD9LvqyxeeLQY48cQT6evrG+MZRUQcWiQ90a7eyemmNwHvUPOVzCtoTgF9FphcvosGmi8o21qWt1KeKC3tRwM7W+sD1qnVdw4yxgvYXmq713ZvT8+vBGFERAzTkCFh+zLb02zPoLnwfIftdwF30nxZGTTfsHlrWV5V3lPa73DzMMYqYEG5++kkYCZwD7AemFnuZJpUxlhV1qmNERERXTCS5yQuBT4kqZ/m+sENpX4DcGypfwhYAr980nQl8CDwLeDi8m2ce4FLgDU0d0+tLH0HGyMiIrrgsHviure317kmERGxfyTda7t3YD1PXEdERFVCIiIiqhISERFRlZCIiIiqhERERFTl37huMWPJ3/xy+fGr3jaGM4mIODjkSCIiIqoSEhERUZWQiIiIqoRERERUJSQiIqIqIREREVUJiYiIqEpIREREVUIiIiKqEhIREVGVkIiIiKqEREREVCUkIiKiasiQkPQSSfdI+p6kTZI+Xuo3SnpM0obyml3qknStpH5JGyWd0rKthZIeKa+FLfU3SLq/rHOtJJX6MZLWlv5rJU054H8CERFR1cmRxLPAGbZfB8wG5kqaU9r+xPbs8tpQaucAM8trMXA9NB/4wOXAacCpwOUtH/rXA+9tWW9uqS8Bbrc9E7i9vI+IiC4ZMiTc+Gl5++Ly8iCrzAduKuutAyZLOgE4G1hre5ft3cBamsA5ATjK9jrbBm4Czm3Z1vKyvLylHhERXdDRNQlJEyRtALbTfNDfXZquLKeUrpF0RKlNBTa3rL6l1Aarb2lTBzje9ray/CPg+Mr8Fkvqk9S3Y8eOTnYpIiI60FFI2H7e9mxgGnCqpJOBy4DfBP4lcAxw6WhNsszBVI5gbC+13Wu7t6enZzSnERExruzX3U22nwLuBOba3lZOKT0L/CXNdQaArcD0ltWmldpg9Wlt6gBPltNRlJ/b92e+ERExMp3c3dQjaXJZPhJ4K/APLR/eorlW8EBZZRVwYbnLaQ6wp5wyWgOcJWlKuWB9FrCmtD0taU7Z1oXArS3b2ncX1MKWekREdMHEDvqcACyXNIEmVFba/qakOyT1AAI2AO8v/VcD84B+4BngIgDbuyR9Alhf+l1he1dZ/gBwI3AkcFt5AVwFrJS0CHgCOH+Y+xkREcMwZEjY3gi8vk39jEp/AxdX2pYBy9rU+4CT29R3AmcONceIiBgdeeI6IiKqEhIREVGVkIiIiKqEREREVCUkIiKiKiERERFVCYmIiKhKSERERFVCIiIiqhISERFRlZCIiIiqhERERFQlJCIioiohERERVQmJiIioSkhERERVQiIiIqoSEhERUTVkSEh6iaR7JH1P0iZJHy/1kyTdLalf0s2SJpX6EeV9f2mf0bKty0r9YUlnt9Tnllq/pCUt9bZjREREd3RyJPEscIbt1wGzgbmS5gBXA9fYfg2wG1hU+i8Cdpf6NaUfkmYBC4DXAnOBz0maIGkCcB1wDjALuKD0ZZAxIiKiC4YMCTd+Wt6+uLwMnAHcUurLgXPL8vzyntJ+piSV+grbz9p+DOgHTi2vftuP2v45sAKYX9apjREREV3Q0TWJ8hv/BmA7sBb4PvCU7b2lyxZgalmeCmwGKO17gGNb6wPWqdWPHWSMgfNbLKlPUt+OHTs62aWIiOhARyFh+3nbs4FpNL/5/+ZoTmp/2V5qu9d2b09Pz1hPJyLisLFfdzfZfgq4E3gjMFnSxNI0DdhalrcC0wFK+9HAztb6gHVq9Z2DjBEREV3Qyd1NPZIml+UjgbcCD9GExXml20Lg1rK8qryntN9h26W+oNz9dBIwE7gHWA/MLHcyTaK5uL2qrFMbIyIiumDi0F04AVhe7kJ6EbDS9jclPQiskPRJ4D7ghtL/BuBLkvqBXTQf+tjeJGkl8CCwF7jY9vMAki4B1gATgGW2N5VtXVoZIyIiumDIkLC9EXh9m/qjNNcnBtZ/Bryzsq0rgSvb1FcDqzsdIyIiuiNPXEdERFVCIiIiqhISERFRlZCIiIiqhERERFQlJCIioiohERERVQmJiIioSkhERERVQiIiIqoSEhERUZWQiIiIqoRERERUJSQiIqIqIREREVUJiYiIqEpIREREVUIiIiKqhgwJSdMl3SnpQUmbJH2w1D8maaukDeU1r2WdyyT1S3pY0tkt9bml1i9pSUv9JEl3l/rNkiaV+hHlfX9pn3FA9z4iIgbVyZHEXuDDtmcBc4CLJc0qbdfYnl1eqwFK2wLgtcBc4HOSJkiaAFwHnAPMAi5o2c7VZVuvAXYDi0p9EbC71K8p/SIiokuGDAnb22x/tyz/BHgImDrIKvOBFbaftf0Y0A+cWl79th+1/XNgBTBfkoAzgFvK+suBc1u2tbws3wKcWfpHREQX7Nc1iXK65/XA3aV0iaSNkpZJmlJqU4HNLattKbVa/VjgKdt7B9RfsK3Svqf0HzivxZL6JPXt2LFjf3YpIiIG0XFISHop8FfAH9t+GrgeeDUwG9gGfGo0JtgJ20tt99ru7enpGatpREQcdjoKCUkvpgmIr9j+awDbT9p+3vYvgC/QnE4C2ApMb1l9WqnV6juByZImDqi/YFul/ejSPyIiuqCTu5sE3AA8ZPvTLfUTWrr9LvBAWV4FLCh3Jp0EzATuAdYDM8udTJNoLm6vsm3gTuC8sv5C4NaWbS0sy+cBd5T+ERHRBROH7sKbgHcD90vaUGofobk7aTZg4HHgfQC2N0laCTxIc2fUxbafB5B0CbAGmAAss72pbO9SYIWkTwL30YQS5eeXJPUDu2iCJSIiumTIkLD990C7O4pWD7LOlcCVbeqr261n+1H+6XRVa/1nwDuHmmNERIyOPHEdERFVCYmIiKhKSERERFVCIiIiqhISERFRlZCIiIiqhERERFQlJCIioiohERERVQmJiIioSkhERERVQiIiIqoSEhERUZWQiIiIqoRERERUJSQiIqIqIREREVUJiYiIqBoyJCRNl3SnpAclbZL0wVI/RtJaSY+Un1NKXZKuldQvaaOkU1q2tbD0f0TSwpb6GyTdX9a5VpIGGyMiIrqjkyOJvcCHbc8C5gAXS5oFLAFutz0TuL28BzgHmFlei4HrofnABy4HTqP596wvb/nQvx54b8t6c0u9NkZERHTBkCFhe5vt75blnwAPAVOB+cDy0m05cG5Zng/c5MY6YLKkE4CzgbW2d9neDawF5pa2o2yvs23gpgHbajdGRER0wX5dk5A0A3g9cDdwvO1tpelHwPFleSqwuWW1LaU2WH1LmzqDjDFwXosl9Unq27Fjx/7sUkREDKLjkJD0UuCvgD+2/XRrWzkC8AGe2wsMNobtpbZ7bff29PSM5jQiIsaVjkJC0otpAuIrtv+6lJ8sp4ooP7eX+lZgesvq00ptsPq0NvXBxoiIiC7o5O4mATcAD9n+dEvTKmDfHUoLgVtb6heWu5zmAHvKKaM1wFmSppQL1mcBa0rb05LmlLEuHLCtdmNEREQXTOygz5uAdwP3S9pQah8BrgJWSloEPAGcX9pWA/OAfuAZ4CIA27skfQJYX/pdYXtXWf4AcCNwJHBbeTHIGBER0QVDhoTtvwdUaT6zTX8DF1e2tQxY1qbeB5zcpr6z3RgREdEdeeI6IiKqEhIREVGVkIiIiKqEREREVCUkIiKiKiERERFVCYmIiKhKSERERFVCIiIiqhISERFRlZCIiIiqhERERFQlJCIioiohERERVQmJiIioSkhERERVQiIiIqoSEhERUTVkSEhaJmm7pAdaah+TtFXShvKa19J2maR+SQ9LOrulPrfU+iUtaamfJOnuUr9Z0qRSP6K87y/tMw7YXkdEREc6OZK4EZjbpn6N7dnltRpA0ixgAfDass7nJE2QNAG4DjgHmAVcUPoCXF229RpgN7Co1BcBu0v9mtIvIiK6aMiQsH0XsKvD7c0HVth+1vZjQD9wann1237U9s+BFcB8SQLOAG4p6y8Hzm3Z1vKyfAtwZukfERFdMpJrEpdI2lhOR00ptanA5pY+W0qtVj8WeMr23gH1F2yrtO8p/X+FpMWS+iT17dixYwS7FBERrYYbEtcDrwZmA9uATx2oCQ2H7aW2e2339vT0jOVUIiIOK8MKCdtP2n7e9i+AL9CcTgLYCkxv6Tqt1Gr1ncBkSRMH1F+wrdJ+dOkfERFdMqyQkHRCy9vfBfbd+bQKWFDuTDoJmAncA6wHZpY7mSbRXNxeZdvAncB5Zf2FwK0t21pYls8D7ij9IyKiSyYO1UHS14DTgeMkbQEuB06XNBsw8DjwPgDbmyStBB4E9gIX236+bOcSYA0wAVhme1MZ4lJghaRPAvcBN5T6DcCXJPXTXDhfMNKdjYiI/TNkSNi+oE35hja1ff2vBK5sU18NrG5Tf5R/Ol3VWv8Z8M6h5hcREaMnT1xHRERVQiIiIqoSEhERUZWQiIiIqoRERERUJSQiIqIqIREREVUJiYiIqEpIREREVUIiIiKqEhIREVGVkIiIiKqEREREVCUkIiKiKiERERFVCYmIiKhKSERERFVCIiIiqoYMCUnLJG2X9EBL7RhJayU9Un5OKXVJulZSv6SNkk5pWWdh6f+IpIUt9TdIur+sc60kDTZGRER0TydHEjcCcwfUlgC3254J3F7eA5wDzCyvxcD10HzgA5cDp9H8e9aXt3zoXw+8t2W9uUOMERERXTJkSNi+C9g1oDwfWF6WlwPnttRvcmMdMFnSCcDZwFrbu2zvBtYCc0vbUbbX2TZw04BttRsjIiK6ZLjXJI63va0s/wg4vixPBTa39NtSaoPVt7SpDzbGr5C0WFKfpL4dO3YMY3ciIqKdEV+4LkcAPgBzGfYYtpfa7rXd29PTM5pTiYgYV4YbEk+WU0WUn9tLfSswvaXftFIbrD6tTX2wMSIiokuGGxKrgH13KC0Ebm2pX1jucpoD7CmnjNYAZ0maUi5YnwWsKW1PS5pT7mq6cMC22o0RERFdMnGoDpK+BpwOHCdpC81dSlcBKyUtAp4Azi/dVwPzgH7gGeAiANu7JH0CWF/6XWF738XwD9DcQXUkcFt5McgYERHRJUOGhO0LKk1ntulr4OLKdpYBy9rU+4CT29R3thsjIiK6J09cR0REVUIiIiKqEhIREVGVkIiIiKqEREREVCUkIiKiKiERERFVCYmIiKhKSERERFVCIiIiqhISERFRlZCIiIiqhERERFQlJCIioiohERERVQmJiIioSkhERETVkP8y3Xg1Y8nf/HL58aveNoYziYgYOyM6kpD0uKT7JW2Q1Fdqx0haK+mR8nNKqUvStZL6JW2UdErLdhaW/o9IWthSf0PZfn9ZVyOZb0RE7J8DcbrpzbZn2+4t75cAt9ueCdxe3gOcA8wsr8XA9dCECnA5cBpwKnD5vmApfd7bst7cAzDfiIjo0Ghck5gPLC/Ly4FzW+o3ubEOmCzpBOBsYK3tXbZ3A2uBuaXtKNvrbBu4qWVbERHRBSMNCQN/K+leSYtL7Xjb28ryj4Djy/JUYHPLultKbbD6ljb1iIjokpFeuP5t21slvRxYK+kfWhttW5JHOMaQSkAtBjjxxBNHe7iIiHFjREcStreWn9uBr9NcU3iynCqi/Nxeum8FpresPq3UBqtPa1NvN4+ltntt9/b09IxklyIiosWwQ0LSP5P0sn3LwFnAA8AqYN8dSguBW8vyKuDCcpfTHGBPOS21BjhL0pRywfosYE1pe1rSnHJX04Ut24qIiC4Yyemm44Gvl7tSJwJftf0tSeuBlZIWAU8A55f+q4F5QD/wDHARgO1dkj4BrC/9rrC9qyx/ALgROBK4rbwiIqJLhh0Sth8FXtemvhM4s03dwMWVbS0DlrWp9wEnD3eOERExMvlajoiIqEpIREREVUIiIiKqEhIREVGVkIiIiKp8VXgH8rXhETFeJSQiIg5Rrb/Awuj8EpvTTRERUZWQiIiIqoRERERUJSQiIqIqF673U+50iojxJEcSERFRlSOJEchRRUQc7nIkERERVTmSOEByVBERh6OExChIYETEaBn4lPVoS0iMssH+QhMgEdGJbgdDq4TEGKr9xSc8IsansQyDmoM+JCTNBT4LTAC+aPuqMZ7SqDtQ/6EkbCIGdzB+KB9sDuqQkDQBuA54K7AFWC9ple0Hx3Zmh4b8DxARI3Ww3wJ7KtBv+1HbPwdWAPPHeE4REePGQX0kAUwFNre83wKcNrCTpMXA4vL2p5IeHuZ4xwE/Hua6h6rs8/iQfR4HdPWI9vlV7YoHe0h0xPZSYOlItyOpz3bvAZjSISP7PD5kn8eH0djng/1001Zgesv7aaUWERFdcLCHxHpgpqSTJE0CFgCrxnhOERHjxkF9usn2XkmXAGtoboFdZnvTKA454lNWh6Ds8/iQfR4fDvg+y/aB3mZERBwmDvbTTRERMYYSEhERUTUuQ0LSXEkPS+qXtKRN+xGSbi7td0uaMQbTPKA62OcPSXpQ0kZJt0tqe8/0oWSofW7p93uSLOmQvl2yk/2VdH75e94k6avdnuOB1sF/1ydKulPSfeW/7XljMc8DSdIySdslPVBpl6Rry5/JRkmnjGhA2+PqRXMB/PvArwOTgO8Bswb0+QDw+bK8ALh5rOfdhX1+M/BrZfkPx8M+l34vA+4C1gG9Yz3vUf47ngncB0wp718+1vPuwj4vBf6wLM8CHh/reR+A/f43wCnAA5X2ecBtgIA5wN0jGW88Hkl08lUf84HlZfkW4ExJ6uIcD7Qh99n2nbafKW/X0TyTcijr9CtdPgFcDfysm5MbBZ3s73uB62zvBrC9vctzPNA62WcDR5Xlo4EfdnF+o8L2XcCuQbrMB25yYx0wWdIJwx1vPIZEu6/6mFrrY3svsAc4tiuzGx2d7HOrRTS/iRzKhtznchg+3fbh8E2Infwd/wbwG5L+t6R15RuWD2Wd7PPHgN+XtAVYDfxRd6Y2pvb3//dBHdTPSUT3Sfp9oBf4nbGey2iS9CLg08B7xngq3TSR5pTT6TRHindJ+i3bT43lpEbZBcCNtj8l6Y3AlySdbPsXYz2xQ8V4PJLo5Ks+ftlH0kSaw9SdXZnd6Ojo600kvQX4KPAO2892aW6jZah9fhlwMvBtSY/TnLtddQhfvO7k73gLsMr2c7YfA/4vTWgcqjrZ50XASgDb3wFeQvPFf4ezA/p1RuMxJDr5qo9VwMKyfB5wh8sVoUPUkPss6fXAf6MJiEP9XDUMsc+299g+zvYM2zNorsO8w3bf2Ex3xDr57/obNEcRSDqO5vTTo12c44HWyT7/ADgTQNK/oAmJHV2dZfetAi4sdznNAfbY3jbcjY27002ufNWHpCuAPturgBtoDkv7aS4QLRi7GY9ch/v8X4CXAv+9XKP/ge13jNmkR6jDfT5sdLi/a4CzJD0IPA/8ie1D9gi5w33+MPAFSf+e5iL2ew7xX/iQ9DWasD+uXGu5HHgxgO3P01x7mQf0A88AF41ovEP8zysiIkbReDzdFBERHUpIREREVUIiIiKqEhIREVGVkIiIiKqEREREVCUkIiKi6v8Dq6DIjvxjJmkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if INFER_TEST:\n",
    "    # DISPLAY SUBMISSION PREDICTIONS\n",
    "    plt.hist(sub.to_pandas().prediction, bins=100)\n",
    "    plt.title('Test Predictions')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4702.204495,
   "end_time": "2022-05-30T19:08:51.396448",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-30T17:50:29.191953",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
